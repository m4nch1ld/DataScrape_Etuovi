{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping the initial data with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.etuovi.com/myytavat-asunnot/helsinki?haku=M1608807886&sivu=1\"\n",
    "#requesting the URL above:\n",
    "page = requests.get(URL)\n",
    "#specifying the format of “page” using the html parser allowimg python to read the various components of the page, rather than treating it as one long string.\n",
    "soup = bs(page.text, \"html.parser\")\n",
    "#printing soup in a priettier form:\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a while loop for looping through all the \"next pages\".\n",
    "i=0\n",
    "initial_data = []\n",
    "while True:\n",
    "    i = i+1\n",
    "    #Edit the if function below to scrape a larger number of pages\n",
    "    if i > 6:\n",
    "        print(\"done\")\n",
    "        break\n",
    "    else:\n",
    "        #Edit the initial search criteria in at etuovi.com for more specified search.\n",
    "        url = f\"https://www.etuovi.com/myytavat-asunnot/helsinki?haku=M1608933110&sivu=\"+str(i)\n",
    "        page = requests.get(url)\n",
    "        soup = bs(page.text, \"html.parser\")\n",
    "        for div in soup.find_all(name=\"div\", attrs={\"class\":\"flexboxgrid__col-xs-12__1I1LS flexboxgrid__col-sm-7__1EzZq flexboxgrid__col-md-9__2kjy7 flexboxgrid__col-lg-9__M7bfm styles__infoArea__2yhEL\"}):\n",
    "            initial_data.append(div.text.strip())\n",
    "        print(initial_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial = pd.DataFrame(initial_data)\n",
    "df_initial = initial.rename(columns={0: 'Raw_Data'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the initial soup into separated columns for easier readibility and management\n",
    "df_initial[['Type','Raw_2']] = df_initial.Raw_Data.str.split(\"|\",expand=True)\n",
    "df_initial[[\"Raw_3\", \"Year\"]] = df_initial.Raw_2.str.split(\"Vuosi\", expand=True)\n",
    "df_initial['Year_Built'] = df_initial['Year'].str[:4]\n",
    "df_initial[[\"Raw_4\", \"Price_Iteration\"]] = df_initial.Raw_3.str.split(\"Hinta\", expand=True)\n",
    "df_initial[[\"Price\", \"Size\"]] = df_initial.Price_Iteration.str.split(\"Koko\", expand=True)\n",
    "df_initial[[\"Rooms\",\"Address\"]] = df_initial.Raw_3.str.split(\"check\", expand=True)\n",
    "df_initial['Price_Iteration_2'] = df_initial['Price'].str.replace('*',\"\")\n",
    "df_initial['Price_Iteration_3'] = df_initial['Price_Iteration_2'].str.replace('€',\"\")\n",
    "df_initial['Price_Iteration_4'] = df_initial['Price_Iteration_3'].str[:7]\n",
    "df_initial['Price_euro'] = df_initial['Price_Iteration_4'].str.replace(\"\\s+\",\"\")\n",
    "df_initial[\"Size_m²\"] = df_initial[\"Size\"].str.replace(\" m²\",\"\")\n",
    "print(df_initial.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the processed colums, rearrange the columns, and get rid of the raw data\n",
    "data_cleansed = df_initial[[\"Price_euro\",\"Year_Built\",\"Size_m²\",\"Type\",\"Rooms\",\"Address\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the dataframe to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a datetime for naming the excel sheet\n",
    "dt = datetime.now(tz=None)\n",
    "dt_str = dt.strftime(\"%Y\" + \"%m\" + \"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data into Excel (change the file path)\n",
    "data_cleansed.to_excel(r'C:\\Users\\JohnSmith\\NeighborhoodWatch.xlsx', index = False, sheet_name=dt_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
